â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RENDER DEPLOYMENT GUIDE - OUMI CODE ANALYSIS API
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš€ OPTION 1: ONE-CLICK DEPLOY (RECOMMENDED)

1. Push your code to GitHub:
   git add .
   git commit -m "Add Render deployment config"
   git push origin main

2. Go to: https://render.com
   - Sign up/Login (free)
   - Click "New +" â†’ "Blueprint"
   - Connect your GitHub repository
   - Select the repo: assemble-ai
   - Render will auto-detect render.yaml
   - Click "Apply"

3. Add Environment Variable:
   - Go to your service dashboard
   - Environment â†’ Add Environment Variable
   - OPENAI_API_KEY = your_actual_key
   - Save Changes

4. Your API will deploy automatically at:
   https://oumi-code-analyzer.onrender.com

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”§ OPTION 2: MANUAL DEPLOY

1. Go to: https://dashboard.render.com
2. Click "New +" â†’ "Web Service"
3. Connect GitHub repo or use "Public Git repository"
4. Configure:
   - Name: oumi-code-analyzer
   - Runtime: Python 3
   - Build Command: pip install -r requirements.txt
   - Start Command: uvicorn app:app --host 0.0.0.0 --port $PORT
   - Plan: Free

5. Add Environment Variables:
   - OPENAI_API_KEY = your_openai_key
   - PYTHON_VERSION = 3.11.0

6. Click "Create Web Service"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â±ï¸ BUILD TIME: 15-30 minutes (ML dependencies are large)

âœ… ADVANTAGES OF RENDER:
   â€¢ Supports large Docker images (PyTorch, Transformers)
   â€¢ Longer build timeouts (45 mins)
   â€¢ Free tier with 750 hours/month
   â€¢ Auto-deploys on git push
   â€¢ Built-in SSL/HTTPS
   â€¢ Great for ML/AI workloads

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¡ API ENDPOINTS AFTER DEPLOYMENT:

Health Check:
  GET https://oumi-code-analyzer.onrender.com/health

Root:
  GET https://oumi-code-analyzer.onrender.com/

Analyze Code:
  POST https://oumi-code-analyzer.onrender.com/api/analyze
  Content-Type: application/json
  Body: {
    "files": [
      {
        "path": "test.py",
        "content": "def hello():\n  print('hi')"
      }
    ],
    "options": {
      "type": ["bugs", "security"]
    }
  }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ IMPORTANT NOTES:

1. Free tier sleeps after 15 mins of inactivity
   - First request after sleep takes 30-60 seconds
   - Subsequent requests are instant

2. Build takes 15-30 minutes due to:
   - PyTorch (2GB)
   - Transformers (1GB)
   - Tree-sitter libraries
   - CUDA dependencies

3. Service will be available at:
   https://oumi-code-analyzer.onrender.com
   (URL may vary based on availability)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ”¥ QUICK DEPLOY:

cd /Users/pkroot/Desktop/open-source/assemble-ai/oumi
git add .
git commit -m "Add Render config"
git push origin main

Then go to: https://render.com/deploy

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
